{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.container\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "# import hyperopt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n0   1          1          0          0       1381         63          0   \n1   2          0          0          0       1809         33          1   \n2   3          0          0          0       1804         29          0   \n3   4          0          0          0       1560         28          1   \n4   5          0          0          0        258         33          1   \n\n   feature_7  feature_8  feature_9  ...  feature_116  feature_117  \\\n0          0          1          0  ...            0            0   \n1          0          1          0  ...            0            0   \n2          1          0          0  ...            0            0   \n3          1          0          0  ...            0            0   \n4          0          0          0  ...            0            0   \n\n   feature_118  feature_119  feature_120  feature_121  feature_122  \\\n0            0          0.0         7000         4000    7526.3157   \n1            0          0.0        10000         1000    8393.4426   \n2            0          0.0         3000         1000    3425.9259   \n3            0          0.0         2000         1000    1946.6666   \n4            0          0.0         2000         2000    4444.4444   \n\n   feature_123  feature_124  target  \n0        12000     0.583333       0  \n1        30000     0.333333       0  \n2        15000     0.200000       0  \n3         3000     0.666667       0  \n4         8000     0.250000       0  \n\n[5 rows x 126 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>feature_116</th>\n      <th>feature_117</th>\n      <th>feature_118</th>\n      <th>feature_119</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n      <th>feature_122</th>\n      <th>feature_123</th>\n      <th>feature_124</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1381</td>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>7000</td>\n      <td>4000</td>\n      <td>7526.3157</td>\n      <td>12000</td>\n      <td>0.583333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1809</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>10000</td>\n      <td>1000</td>\n      <td>8393.4426</td>\n      <td>30000</td>\n      <td>0.333333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1804</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3000</td>\n      <td>1000</td>\n      <td>3425.9259</td>\n      <td>15000</td>\n      <td>0.200000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1560</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>1946.6666</td>\n      <td>3000</td>\n      <td>0.666667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>258</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>4444.4444</td>\n      <td>8000</td>\n      <td>0.250000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 126 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', sep=';')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ID неинформативный столбец, уберем его"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = df.drop('ID', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255820 entries, 0 to 255819\n",
      "Columns: 125 entries, feature_1 to target\n",
      "dtypes: float64(21), int64(104)\n",
      "memory usage: 244.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "feature_106    41893\nfeature_102    37795\nfeature_103    37795\nfeature_104    37795\nfeature_105    37795\n               ...  \nfeature_38         0\nfeature_37         0\nfeature_36         0\nfeature_35         0\ntarget             0\nLength: 125, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "193073"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull().sum().sort_values(ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Борьбу с пропусками осуществим в несколько вариантов: удалим те строки, где пропуски в данных. Однако это черевато тем, что в худшем случае у нас из 255_820 данных 193_073 будут составлять пропуски. Второй вариант, это заполнить пропуски средним значением по столбцу (однако этот метод плохо работает с категориальными признаками). Лучшим способом было бы использовать KNNInputer, который ищет ближайших соседей и вставляет в данную ячейку среднее значение соседей. Но данный метод работает долго"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213927 entries, 0 to 213926\n",
      "Columns: 125 entries, feature_1 to target\n",
      "dtypes: float64(21), int64(104)\n",
      "memory usage: 204.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_drop_null = df.dropna()\n",
    "df_drop_null.reset_index(inplace=True, drop=True)\n",
    "df_drop_null.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255820 entries, 0 to 255819\n",
      "Columns: 125 entries, feature_1 to target\n",
      "dtypes: float64(16), int64(104), object(5)\n",
      "memory usage: 244.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_mean_null = df.fillna(df.mean)\n",
    "df_mean_null.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### После удаления пустых значений сохранили 83.6% исходного датасета. Используем очищенный датасет"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# imputer = KNNImputer(n_neighbors=2)\n",
    "# df_knn_null =imputer.fit_transform(df.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# df['target'].plot.bar()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Удалим высококоррелированные столбцы"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def trimm_correlated(df_in, threshold=0.3):\n",
    "    df_corr = df_in.corr(method='pearson', min_periods=1)\n",
    "    df_not_correlated = ~(df_corr.mask(np.tril(np.ones([len(df_corr)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    df_correlated = (df_corr.mask(np.tril(np.ones([len(df_corr)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n",
    "    cors = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == False]\n",
    "    df_out = df_in[un_corr_idx]\n",
    "    return df_out, cors.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "        feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n0               1          0          0       1381         63          0   \n1               0          0          0       1809         33          1   \n2               0          0          0       1804         29          0   \n3               0          0          0       1560         28          1   \n4               0          0          0        258         33          1   \n...           ...        ...        ...        ...        ...        ...   \n213922          0          0          0         63         66          0   \n213923          0          0          0        501         29          0   \n213924          1          0          0         99         64          0   \n213925          0          0          0         43         33          0   \n213926          0          0          0        159         57          1   \n\n        feature_7  feature_9  feature_10  feature_11  ...  feature_102  \\\n0               0          0           0           0  ...         61.0   \n1               0          0           0           1  ...          0.0   \n2               1          0           0           1  ...         16.0   \n3               1          0           0           0  ...          5.0   \n4               0          0           1           0  ...          1.0   \n...           ...        ...         ...         ...  ...          ...   \n213922          0          0           1           0  ...         10.0   \n213923          1          0           0           1  ...         26.0   \n213924          0          0           0           0  ...         21.0   \n213925          1          0           0           0  ...         23.0   \n213926          1          0           0           1  ...         58.0   \n\n        feature_106  feature_107  feature_108  feature_110  feature_111  \\\n0          0.610000            0            4            0            0   \n1          0.000000            1            5            0            0   \n2          0.139130            0            3            0            5   \n3          0.043103            0            0            0            0   \n4          0.071429            0            0            0            0   \n...             ...          ...          ...          ...          ...   \n213922     0.909091            0            0            0            0   \n213923     0.313253            0            1            0            0   \n213924     0.777778            0            0            0            0   \n213925     1.000000            0            0            0            0   \n213926     1.000000            0            0            0            0   \n\n        feature_116  feature_120  feature_121  target  \n0                 0         7000         4000       0  \n1                 0        10000         1000       0  \n2                 0         3000         1000       0  \n3                 0         2000         1000       0  \n4                 0         2000         2000       0  \n...             ...          ...          ...     ...  \n213922            0         1150         1150       0  \n213923            0         3000         1000       0  \n213924            0         5800         2400       0  \n213925            0         2000         2000       0  \n213926            0         1000         1000       0  \n\n[213927 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>...</th>\n      <th>feature_102</th>\n      <th>feature_106</th>\n      <th>feature_107</th>\n      <th>feature_108</th>\n      <th>feature_110</th>\n      <th>feature_111</th>\n      <th>feature_116</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1381</td>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>61.0</td>\n      <td>0.610000</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7000</td>\n      <td>4000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1809</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1804</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>16.0</td>\n      <td>0.139130</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1560</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>0.043103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>258</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.071429</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213922</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63</td>\n      <td>66</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>0.909091</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1150</td>\n      <td>1150</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213923</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>501</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>26.0</td>\n      <td>0.313253</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213924</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>99</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>0.777778</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5800</td>\n      <td>2400</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213925</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>33</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>23.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213926</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>159</td>\n      <td>57</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>58.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>213927 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_correlated_drop, corr = trimm_correlated(df_drop_null, threshold=0.5)\n",
    "df_non_correlated_drop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запомним имена высокоррелированных столбцов. Нам они понадобятся при чистке verify.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['feature_8', 'feature_12', 'feature_16', 'feature_28', 'feature_30',\n       'feature_31', 'feature_48', 'feature_49', 'feature_55', 'feature_76',\n       'feature_80', 'feature_82', 'feature_83', 'feature_84', 'feature_86',\n       'feature_87', 'feature_93', 'feature_94', 'feature_96', 'feature_97',\n       'feature_98', 'feature_99', 'feature_100', 'feature_101', 'feature_103',\n       'feature_104', 'feature_105', 'feature_109', 'feature_112',\n       'feature_113', 'feature_114', 'feature_115', 'feature_117',\n       'feature_118', 'feature_119', 'feature_122', 'feature_123',\n       'feature_124'],\n      dtype='object')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Посмотрим c какими типами значений (категориальные (0, 1, ..., N) или рациональные) нам приходится сталкиваться"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "           feature_1      feature_2      feature_3      feature_4  \\\ncount  213927.000000  213927.000000  213927.000000  213927.000000   \nmean        0.346679       0.000019       0.001094     943.315178   \nstd         0.475914       0.004324       0.033055     766.946139   \nmin         0.000000       0.000000       0.000000       1.000000   \n25%         0.000000       0.000000       0.000000     285.000000   \n50%         0.000000       0.000000       0.000000     746.000000   \n75%         1.000000       0.000000       0.000000    1465.000000   \nmax         1.000000       1.000000       1.000000    3451.000000   \n\n           feature_5      feature_6      feature_7      feature_9  \\\ncount  213927.000000  213927.000000  213927.000000  213927.000000   \nmean       41.278422       0.412487       0.348264       0.063863   \nstd        13.666285       0.492283       0.476421       0.244509   \nmin        18.000000       0.000000       0.000000       0.000000   \n25%        30.000000       0.000000       0.000000       0.000000   \n50%        38.000000       0.000000       0.000000       0.000000   \n75%        52.000000       1.000000       1.000000       0.000000   \nmax        82.000000       1.000000       1.000000       1.000000   \n\n         feature_10     feature_11  ...    feature_102    feature_106  \\\ncount  213927.00000  213927.000000  ...  213927.000000  213927.000000   \nmean        0.14196       0.248066  ...      61.142469       0.352597   \nstd         0.34901       0.431891  ...     196.644212       0.518324   \nmin         0.00000       0.000000  ...    -490.000000     -76.600000   \n25%         0.00000       0.000000  ...       4.000000       0.031646   \n50%         0.00000       0.000000  ...      12.000000       0.146341   \n75%         0.00000       0.000000  ...      33.000000       0.752187   \nmax         1.00000       1.000000  ...    3278.000000       9.428571   \n\n         feature_107    feature_108    feature_110    feature_111  \\\ncount  213927.000000  213927.000000  213927.000000  213927.000000   \nmean        0.076026       1.233257       0.067841       0.485053   \nstd         0.265040       2.658280       0.258241       1.289681   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.000000       0.000000       0.000000       0.000000   \n50%         0.000000       0.000000       0.000000       0.000000   \n75%         0.000000       1.000000       0.000000       0.000000   \nmax         1.000000      67.000000       6.000000      32.000000   \n\n         feature_116    feature_120    feature_121         target  \ncount  213927.000000  213927.000000  213927.000000  213927.000000  \nmean        0.014860    7394.408494    2298.540703       0.164149  \nstd         0.120994    8447.649726    2144.660777       0.370412  \nmin         0.000000    1000.000000    1000.000000       0.000000  \n25%         0.000000    2000.000000    1000.000000       0.000000  \n50%         0.000000    4000.000000    2000.000000       0.000000  \n75%         0.000000   10000.000000    2000.000000       0.000000  \nmax         1.000000   99000.000000   44000.000000       1.000000  \n\n[8 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>...</th>\n      <th>feature_102</th>\n      <th>feature_106</th>\n      <th>feature_107</th>\n      <th>feature_108</th>\n      <th>feature_110</th>\n      <th>feature_111</th>\n      <th>feature_116</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.00000</td>\n      <td>213927.000000</td>\n      <td>...</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n      <td>213927.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.346679</td>\n      <td>0.000019</td>\n      <td>0.001094</td>\n      <td>943.315178</td>\n      <td>41.278422</td>\n      <td>0.412487</td>\n      <td>0.348264</td>\n      <td>0.063863</td>\n      <td>0.14196</td>\n      <td>0.248066</td>\n      <td>...</td>\n      <td>61.142469</td>\n      <td>0.352597</td>\n      <td>0.076026</td>\n      <td>1.233257</td>\n      <td>0.067841</td>\n      <td>0.485053</td>\n      <td>0.014860</td>\n      <td>7394.408494</td>\n      <td>2298.540703</td>\n      <td>0.164149</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.475914</td>\n      <td>0.004324</td>\n      <td>0.033055</td>\n      <td>766.946139</td>\n      <td>13.666285</td>\n      <td>0.492283</td>\n      <td>0.476421</td>\n      <td>0.244509</td>\n      <td>0.34901</td>\n      <td>0.431891</td>\n      <td>...</td>\n      <td>196.644212</td>\n      <td>0.518324</td>\n      <td>0.265040</td>\n      <td>2.658280</td>\n      <td>0.258241</td>\n      <td>1.289681</td>\n      <td>0.120994</td>\n      <td>8447.649726</td>\n      <td>2144.660777</td>\n      <td>0.370412</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-490.000000</td>\n      <td>-76.600000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>285.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>0.031646</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2000.000000</td>\n      <td>1000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>746.000000</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>12.000000</td>\n      <td>0.146341</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4000.000000</td>\n      <td>2000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1465.000000</td>\n      <td>52.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>33.000000</td>\n      <td>0.752187</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10000.000000</td>\n      <td>2000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3451.000000</td>\n      <td>82.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>3278.000000</td>\n      <td>9.428571</td>\n      <td>1.000000</td>\n      <td>67.000000</td>\n      <td>6.000000</td>\n      <td>32.000000</td>\n      <td>1.000000</td>\n      <td>99000.000000</td>\n      <td>44000.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_correlated_drop.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Столбцы с минимальным значением 0 проверим на категориальные фичи по признаку: если количество уникальных значений (напр. 0, 1, 2) равно максимальному значению по выборке (в нашем случае 2) + 1, значит фича категориальная и её не будем использовать в нормализации и проверке на выбросы.\n",
    "### Категориальные фичи нельзя использовать в нормализации, поскольку если 1-Москва, а 2-Спб, то что тогда 1.5??\n",
    "\n",
    "### Получим имена категориальных и рациональных фич"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "category_features = []\n",
    "rational_features = []\n",
    "\n",
    "for col_name in df_non_correlated_drop.columns:\n",
    "    if (df_non_correlated_drop.describe()[col_name]['min'] == 0) and (df_non_correlated_drop.describe()[col_name]['max'] + 1 == len(pd.unique(df_non_correlated_drop[col_name]))):\n",
    "        category_features.append(col_name)\n",
    "    else:\n",
    "        rational_features.append(col_name)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "67"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rational_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Рассмотрим распределение по классам target-а"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x21dab3698e0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df_non_correlated_drop, x=\"target\", height=8,aspect=1.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "5.09200934047158"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = len(df_non_correlated_drop[df_non_correlated_drop['target'] == 0]) / len(df_non_correlated_drop[df_non_correlated_drop['target'] == 1])\n",
    "scale_pos_weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Борьба с выбросами интерквантильным размахом"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_4       1180.000000\n",
      "feature_5         22.000000\n",
      "feature_19         3.700000\n",
      "feature_47      5000.000000\n",
      "feature_50     23000.000000\n",
      "feature_53         0.000000\n",
      "feature_54       400.000000\n",
      "feature_85         4.000000\n",
      "feature_88         0.694853\n",
      "feature_89         0.385570\n",
      "feature_90         1.000000\n",
      "feature_91         6.000000\n",
      "feature_92         0.000000\n",
      "feature_95         1.000000\n",
      "feature_102       29.000000\n",
      "feature_106        0.720541\n",
      "feature_108        1.000000\n",
      "feature_111        0.000000\n",
      "feature_120     8000.000000\n",
      "feature_121     1000.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1 = df_non_correlated_drop[rational_features].quantile(0.25)\n",
    "Q3 = df_non_correlated_drop[rational_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df_non_correlated_drop_o = df_non_correlated_drop[~((df_non_correlated_drop[rational_features] < (Q1 - 1.5 * IQR)) |(df_non_correlated_drop[rational_features] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "        feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n3               0          0          0       1560         28          1   \n4               0          0          0        258         33          1   \n5               0          0          0        377         48          1   \n6               0          0          0       2442         66          1   \n8               1          0          0        526         27          0   \n...           ...        ...        ...        ...        ...        ...   \n213921          0          0          0       1491         63          1   \n213922          0          0          0         63         66          0   \n213924          1          0          0         99         64          0   \n213925          0          0          0         43         33          0   \n213926          0          0          0        159         57          1   \n\n        feature_7  feature_9  feature_10  feature_11  ...  feature_102  \\\n3               1          0           0           0  ...          5.0   \n4               0          0           1           0  ...          1.0   \n5               0          0           0           0  ...          1.0   \n6               0          0           1           1  ...         21.0   \n8               0          0           0           1  ...         74.0   \n...           ...        ...         ...         ...  ...          ...   \n213921          0          0           1           0  ...         46.0   \n213922          0          0           1           0  ...         10.0   \n213924          0          0           0           0  ...         21.0   \n213925          1          0           0           0  ...         23.0   \n213926          1          0           0           1  ...         58.0   \n\n        feature_106  feature_107  feature_108  feature_110  feature_111  \\\n3          0.043103            0            0            0            0   \n4          0.071429            0            0            0            0   \n5          0.003534            0            0            0            0   \n6          0.064024            0            0            0            0   \n8          1.000000            0            0            0            0   \n...             ...          ...          ...          ...          ...   \n213921     0.389831            0            0            0            0   \n213922     0.909091            0            0            0            0   \n213924     0.777778            0            0            0            0   \n213925     1.000000            0            0            0            0   \n213926     1.000000            0            0            0            0   \n\n        feature_116  feature_120  feature_121  target  \n3                 0         2000         1000       0  \n4                 0         2000         2000       0  \n5                 0         2000         2000       0  \n6                 0         2000         1000       0  \n8                 0         2000         1000       0  \n...             ...          ...          ...     ...  \n213921            0         1000         1000       1  \n213922            0         1150         1150       0  \n213924            0         5800         2400       0  \n213925            0         2000         2000       0  \n213926            0         1000         1000       0  \n\n[66786 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>...</th>\n      <th>feature_102</th>\n      <th>feature_106</th>\n      <th>feature_107</th>\n      <th>feature_108</th>\n      <th>feature_110</th>\n      <th>feature_111</th>\n      <th>feature_116</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1560</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>0.043103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>258</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.071429</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>377</td>\n      <td>48</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.003534</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2442</td>\n      <td>66</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>0.064024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>526</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>74.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>213921</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1491</td>\n      <td>63</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>46.0</td>\n      <td>0.389831</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>213922</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63</td>\n      <td>66</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>0.909091</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1150</td>\n      <td>1150</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213924</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>99</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>0.777778</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5800</td>\n      <td>2400</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213925</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>33</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>23.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>213926</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>159</td>\n      <td>57</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>58.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>66786 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_correlated_drop_o"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Видно, что классы несбалансированны. Класс target == 0 в 5 раз больше target == 1. Поэтому разбивать на тренировку и тест нужно с условием несбалансированности классов. Либо можно попробовать использовать различные методы семплирования и десемплирования выборок, а также добавлением весов в классы.\n",
    "## Я буду использовать разбиение по классам и применение весов для дисбаланса классов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Метод разбиения stratify по классам"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_non_correlated_drop.iloc[:, :-1], df_non_correlated_drop.iloc[:, -1], test_size=0.33, random_state=42, stratify=df_non_correlated_drop['target'])\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[rational_features] = scaler.fit_transform(X_train[rational_features].values)\n",
    "X_test[rational_features] = scaler.transform(X_test[rational_features].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base model for stratify spliting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "classes = np.unique(y_train.values.ravel())\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train.values.ravel())\n",
    "class_weights = dict(zip(classes, weights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 model run_time      rmse  f1_score   ROC_AUC  logisticloss\n0  LogisticRegression      0.19  0.553654  0.424682  0.691772     10.587477\n1             CatBoost     1.48  0.532714  0.451964  0.714881      9.801734\n2                 LGMB     0.01  0.543337  0.446792  0.713417     10.196566\n3                 XGBM     0.15  0.526253  0.445849  0.705242      9.565418",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>run_time</th>\n      <th>rmse</th>\n      <th>f1_score</th>\n      <th>ROC_AUC</th>\n      <th>logisticloss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.19</td>\n      <td>0.553654</td>\n      <td>0.424682</td>\n      <td>0.691772</td>\n      <td>10.587477</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>1.48</td>\n      <td>0.532714</td>\n      <td>0.451964</td>\n      <td>0.714881</td>\n      <td>9.801734</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LGMB</td>\n      <td>0.01</td>\n      <td>0.543337</td>\n      <td>0.446792</td>\n      <td>0.713417</td>\n      <td>10.196566</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBM</td>\n      <td>0.15</td>\n      <td>0.526253</td>\n      <td>0.445849</td>\n      <td>0.705242</td>\n      <td>9.565418</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_models(X_train=X_train, X_test=X_test, y_test = y_test.values.ravel(), y_train = y_train.values.ravel()):\n",
    "    regressors = {\n",
    "        \"LogisticRegression \": LogisticRegression(random_state=1, max_iter=10000, class_weight=class_weights),\n",
    "        'CatBoost': CatBoostClassifier(iterations=10000,\n",
    "                                       task_type=\"GPU\",\n",
    "                                       devices='0:1', eval_metric='TotalF1',\n",
    "                                       class_weights=class_weights, verbose=False,\n",
    "                                       loss_function='Logloss'),\n",
    "        'LGMB': LGBMClassifier(class_weight='balanced', n_estimators=50),\n",
    "        'XGBM': xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "    }\n",
    "\n",
    "    df_models = pd.DataFrame(columns=['model', 'run_time','rmse', 'f1_score', 'ROC_AUC', 'logisticloss'])\n",
    "\n",
    "    for key in regressors:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        regressor = regressors[key]\n",
    "        model = regressor.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # scores = cross_val_score(model,\n",
    "        #                          X_train,\n",
    "        #                          y_train.values.ravel(),\n",
    "        #                          scoring='f1',\n",
    "        #                          cv=10)\n",
    "\n",
    "\n",
    "        row = {'model': key,\n",
    "               'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "               'rmse': (np.sqrt(mean_squared_error(y_test, y_pred))),\n",
    "               'f1_score': f1_score(y_test, y_pred),\n",
    "               'ROC_AUC': roc_auc_score(y_test, y_pred),\n",
    "               'logisticloss': log_loss(y_test, y_pred)\n",
    "               }\n",
    "\n",
    "        df_models = df_models.append(row, ignore_index=True)\n",
    "    return df_models\n",
    "base_models().head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Попробуем технику UNDERSAMPLING для борьбы с несбалансированностью классов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 model run_time      rmse  f1_score   ROC_AUC  logisticloss\n0  LogisticRegression      0.06  0.866197  0.301785  0.546290     25.914955\n1             CatBoost     6.36  0.812488  0.326478  0.594953     22.800833\n2                 LGMB     0.01  0.542058  0.446337  0.712341     10.148618\n3                 XGBM     0.06  0.772513  0.341451  0.619921     20.612383",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>run_time</th>\n      <th>rmse</th>\n      <th>f1_score</th>\n      <th>ROC_AUC</th>\n      <th>logisticloss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.06</td>\n      <td>0.866197</td>\n      <td>0.301785</td>\n      <td>0.546290</td>\n      <td>25.914955</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>6.36</td>\n      <td>0.812488</td>\n      <td>0.326478</td>\n      <td>0.594953</td>\n      <td>22.800833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LGMB</td>\n      <td>0.01</td>\n      <td>0.542058</td>\n      <td>0.446337</td>\n      <td>0.712341</td>\n      <td>10.148618</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBM</td>\n      <td>0.06</td>\n      <td>0.772513</td>\n      <td>0.341451</td>\n      <td>0.619921</td>\n      <td>20.612383</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train.values.ravel())\n",
    "base_models(X_train=X_res, X_test=X_test, y_test=y_test, y_train=y_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Попробуем технику OVERSAMPLING для борьбы с несбалансированностью классов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\.conda\\envs\\raifhack_2021\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:35:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 model run_time      rmse  f1_score   ROC_AUC  logisticloss\n0  LogisticRegression       0.4  0.864380  0.302523  0.547894     25.806340\n1             CatBoost     1.45  0.787072  0.336947  0.612926     21.396664\n2                 LGMB     0.02  0.541391  0.446501  0.712253     10.123666\n3                 XGBM     0.24  0.757533  0.345398  0.625517     19.820763",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>run_time</th>\n      <th>rmse</th>\n      <th>f1_score</th>\n      <th>ROC_AUC</th>\n      <th>logisticloss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.4</td>\n      <td>0.864380</td>\n      <td>0.302523</td>\n      <td>0.547894</td>\n      <td>25.806340</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>1.45</td>\n      <td>0.787072</td>\n      <td>0.336947</td>\n      <td>0.612926</td>\n      <td>21.396664</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LGMB</td>\n      <td>0.02</td>\n      <td>0.541391</td>\n      <td>0.446501</td>\n      <td>0.712253</td>\n      <td>10.123666</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBM</td>\n      <td>0.24</td>\n      <td>0.757533</td>\n      <td>0.345398</td>\n      <td>0.625517</td>\n      <td>19.820763</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train.values.ravel())\n",
    "base_models(X_train=X_ros, X_test=X_test, y_test = y_test, y_train = y_ros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Лучше всего (и быстрее) себя ведет LGBM. Его и будем тюнить"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq', 'max_bin'])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'application': 'binary', # for binary classification\n",
    "    #     'num_class' : 1, # used for multi-classes\n",
    "    'boosting': 'gbdt', # traditional gradient boosting decision tree\n",
    "    'num_iterations': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 62,\n",
    "    'device': 'cpu', # you can use GPU to achieve faster learning\n",
    "    'max_depth': -1, # <0 means no limit\n",
    "    'max_bin': 510, # Small number of bins may reduce training accuracy but can deal with over-fitting\n",
    "    'lambda_l1': 5, # L1 regularization\n",
    "    'lambda_l2': 10, # L2 regularization\n",
    "    'metric' : 'binary_error',\n",
    "    'subsample_for_bin': 200, # number of samples for constructing bins\n",
    "    'subsample': 1, # subsample ratio of the training instance\n",
    "    'colsample_bytree': 0.8, # subsample ratio of columns when constructing the tree\n",
    "    'min_split_gain': 0.5, # minimum loss reduction required to make further partition on a leaf node of the tree\n",
    "    'min_child_weight': 1, # minimum sum of instance weight (hessian) needed in a leaf\n",
    "    'min_child_samples': 5# minimum number of data needed in a leaf\n",
    "}\n",
    "\n",
    "# Initiate classifier to use\n",
    "mdl = LGBMClassifier(boosting_type= 'gbdt',\n",
    "                     objective = 'binary',\n",
    "                     class_weight=class_weights,\n",
    "                     n_jobs = 6,\n",
    "                     silent = True,\n",
    "                     max_depth = params['max_depth'],\n",
    "                     max_bin = params['max_bin'],\n",
    "                     subsample_for_bin = params['subsample_for_bin'],\n",
    "                     subsample = params['subsample'],\n",
    "                     min_split_gain = params['min_split_gain'],\n",
    "                     min_child_weight = params['min_child_weight'],\n",
    "                     min_child_samples = params['min_child_samples'])\n",
    "\n",
    "# To view the default model parameters:\n",
    "mdl.get_params().keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3456 candidates, totalling 13824 fits\n",
      "{'boosting_type': 'dart', 'colsample_bytree': 0.66, 'learning_rate': 0.01, 'max_bin': 255, 'n_estimators': 16, 'num_leaves': 6, 'objective': 'binary', 'random_state': 500, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.7063162467415778\n"
     ]
    }
   ],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [500],\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "# Run the grid\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4214563305379423"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(boosting_type='dart',colsample_bytree=0.66, learning_rate=0.01, max_bin=255,n_estimators=16, num_leaves=6, random_state=500, reg_alpha=1, reg_lambda=1,subsample=0.7 ,objective = 'binary', class_weight=class_weights)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Лучшие метрики я получил на LGBMC при стандартных гиперпараметрах, его и буду использовать для получения конечного результата"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проверим модель на переобученность. Если метрика на test-выборке сильно меньше метрики на train-выборке, значит модель сильно переобучилась"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "LGBMClassifier(class_weight='balanced', n_estimators=50)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LGBMClassifier(class_weight='balanced', n_estimators=50)\n",
    "clf.fit(X_train, y_train.values.ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метрики на train-выборке"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0.45821559392987965"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, clf.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метрики на test-выборке"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4467921322963395"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, clf.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метрики практически индентичны. Это значит, что модель не явлвяется переобученной. Используем её для получения финального результата"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.24640163, 0.24870044, 0.59011239, ..., 0.79243171, 0.30125532,\n       0.18688952])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X_test)\n",
    "y_pred[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame({'Вероятность':np.squeeze(y_pred[:, -1]), 'target':np.squeeze(y_test.values)})\n",
    "group_df\n",
    "group_df.to_excel('group.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "           ID  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n0      255821          0          0          0       2268         34   \n1      255822          0          0          0         42         49   \n2      255823          0          0          0        265         69   \n3      255824          1          0          0        834         25   \n4      255825          0          0          0        772         26   \n...       ...        ...        ...        ...        ...        ...   \n56025  311846          0          0          0         58         27   \n56026  311847          1          0          0        131         28   \n56027  311848          0          0          0        199         32   \n56028  311849          0          0          0        904         56   \n56029  311850          0          0          0         52         61   \n\n       feature_6  feature_7  feature_8  feature_9  ...  feature_115  \\\n0              0          1          0          0  ...            1   \n1              0          0          1          0  ...            0   \n2              0          1          0          0  ...            0   \n3              1          0          1          0  ...            0   \n4              1          1          0          0  ...            1   \n...          ...        ...        ...        ...  ...          ...   \n56025          0          0          1          0  ...            0   \n56026          0          0          1          0  ...            0   \n56027          0          0          1          0  ...            0   \n56028          1          1          0          0  ...            0   \n56029          0          1          0          0  ...            0   \n\n       feature_116  feature_117  feature_118  feature_119  feature_120  \\\n0                0            0            0          0.0         6000   \n1                0            0            0          0.0         6000   \n2                0            0            0          0.0         3000   \n3                0            0            0          0.0         2000   \n4                0            0            0          0.0         8000   \n...            ...          ...          ...          ...          ...   \n56025            0            0            0          0.0         3000   \n56026            0            0            0          0.0        12000   \n56027            0            1            2          0.2        30000   \n56028            0            0            0          0.0         2400   \n56029            1            1            2          0.5        24500   \n\n       feature_121  feature_122  feature_123  feature_124  \n0             1000    4551.0204        12000     0.500000  \n1             3400    4700.0000         6000     1.000000  \n2             3000    4133.3333         6000     0.500000  \n3             1000    3875.0000        11000     0.181818  \n4             2000    7640.0000        12000     0.666667  \n...            ...          ...          ...          ...  \n56025         2500    3100.0000         4000     0.750000  \n56026         4000    8137.5000        12000     1.000000  \n56027        30000   30620.0000        36200     0.828729  \n56028         1000    3007.1428        10000     0.240000  \n56029         9950   16350.0000        24500     1.000000  \n\n[56030 rows x 125 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>feature_115</th>\n      <th>feature_116</th>\n      <th>feature_117</th>\n      <th>feature_118</th>\n      <th>feature_119</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n      <th>feature_122</th>\n      <th>feature_123</th>\n      <th>feature_124</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>255821</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2268</td>\n      <td>34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>6000</td>\n      <td>1000</td>\n      <td>4551.0204</td>\n      <td>12000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>255822</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>6000</td>\n      <td>3400</td>\n      <td>4700.0000</td>\n      <td>6000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>255823</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>265</td>\n      <td>69</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3000</td>\n      <td>3000</td>\n      <td>4133.3333</td>\n      <td>6000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>255824</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>834</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2000</td>\n      <td>1000</td>\n      <td>3875.0000</td>\n      <td>11000</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>255825</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>772</td>\n      <td>26</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>8000</td>\n      <td>2000</td>\n      <td>7640.0000</td>\n      <td>12000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56025</th>\n      <td>311846</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3000</td>\n      <td>2500</td>\n      <td>3100.0000</td>\n      <td>4000</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>56026</th>\n      <td>311847</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>131</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>12000</td>\n      <td>4000</td>\n      <td>8137.5000</td>\n      <td>12000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>56027</th>\n      <td>311848</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>199</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.2</td>\n      <td>30000</td>\n      <td>30000</td>\n      <td>30620.0000</td>\n      <td>36200</td>\n      <td>0.828729</td>\n    </tr>\n    <tr>\n      <th>56028</th>\n      <td>311849</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>904</td>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2400</td>\n      <td>1000</td>\n      <td>3007.1428</td>\n      <td>10000</td>\n      <td>0.240000</td>\n    </tr>\n    <tr>\n      <th>56029</th>\n      <td>311850</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>52</td>\n      <td>61</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.5</td>\n      <td>24500</td>\n      <td>9950</td>\n      <td>16350.0000</td>\n      <td>24500</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>56030 rows × 125 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_df = pd.read_csv('verify.csv', sep=';')\n",
    "verify_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Удаляем коррелированные стобцы и центрируем"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "           ID  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n0      255821          0          0          0       2268         34   \n1      255822          0          0          0         42         49   \n2      255823          0          0          0        265         69   \n3      255824          1          0          0        834         25   \n4      255825          0          0          0        772         26   \n...       ...        ...        ...        ...        ...        ...   \n56025  311846          0          0          0         58         27   \n56026  311847          1          0          0        131         28   \n56027  311848          0          0          0        199         32   \n56028  311849          0          0          0        904         56   \n56029  311850          0          0          0         52         61   \n\n       feature_6  feature_7  feature_9  feature_10  ...  feature_95  \\\n0              0          1          0           0  ...       0.875   \n1              0          0          0           0  ...       1.000   \n2              0          1          0           0  ...       1.000   \n3              1          0          0           0  ...       1.000   \n4              1          1          0           0  ...       0.000   \n...          ...        ...        ...         ...  ...         ...   \n56025          0          0          0           0  ...       1.000   \n56026          0          0          0           0  ...       1.000   \n56027          0          0          0           0  ...       1.000   \n56028          1          1          0           0  ...       0.000   \n56029          0          1          0           0  ...       1.000   \n\n       feature_102  feature_106  feature_107  feature_108  feature_110  \\\n0             42.0     0.175732            0            2            0   \n1             20.0     1.000000            0            0            0   \n2            203.0     1.000000            0            0            0   \n3             15.0     0.081081            0            1            0   \n4            142.0     0.290984            0            0            0   \n...            ...          ...          ...          ...          ...   \n56025          7.0     1.000000            0            0            0   \n56026         11.0     0.183333            0            0            0   \n56027          4.0     0.500000            0            2            0   \n56028         25.0     0.074405            0            0            0   \n56029          5.0     0.555556            0            0            0   \n\n       feature_111  feature_116  feature_120  feature_121  \n0                1            0         6000         1000  \n1                0            0         6000         3400  \n2                0            0         3000         3000  \n3                0            0         2000         1000  \n4                1            0         8000         2000  \n...            ...          ...          ...          ...  \n56025            0            0         3000         2500  \n56026            0            0        12000         4000  \n56027            0            0        30000        30000  \n56028            0            0         2400         1000  \n56029            0            1        24500         9950  \n\n[56030 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>...</th>\n      <th>feature_95</th>\n      <th>feature_102</th>\n      <th>feature_106</th>\n      <th>feature_107</th>\n      <th>feature_108</th>\n      <th>feature_110</th>\n      <th>feature_111</th>\n      <th>feature_116</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>255821</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2268</td>\n      <td>34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.875</td>\n      <td>42.0</td>\n      <td>0.175732</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>255822</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>20.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>3400</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>255823</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>265</td>\n      <td>69</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>203.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>255824</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>834</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>15.0</td>\n      <td>0.081081</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2000</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>255825</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>772</td>\n      <td>26</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>142.0</td>\n      <td>0.290984</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8000</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56025</th>\n      <td>311846</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>7.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>56026</th>\n      <td>311847</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>131</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>11.0</td>\n      <td>0.183333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>56027</th>\n      <td>311848</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>199</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>4.0</td>\n      <td>0.500000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30000</td>\n      <td>30000</td>\n    </tr>\n    <tr>\n      <th>56028</th>\n      <td>311849</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>904</td>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>25.0</td>\n      <td>0.074405</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2400</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>56029</th>\n      <td>311850</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>52</td>\n      <td>61</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>5.0</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>24500</td>\n      <td>9950</td>\n    </tr>\n  </tbody>\n</table>\n<p>56030 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in corr.values:\n",
    "    verify_df.drop(name, inplace=True, axis=1)\n",
    "verify_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "           ID  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n0      255821          0          0          0   1.733257  -0.530214   \n1      255822          0          0          0  -1.173292   0.568832   \n2      255823          0          0          0  -0.882115   2.034226   \n3      255824          1          0          0  -0.139156  -1.189641   \n4      255825          0          0          0  -0.220111  -1.116372   \n...       ...        ...        ...        ...        ...        ...   \n56025  311846          0          0          0  -1.152401  -1.043102   \n56026  311847          1          0          0  -1.057083  -0.969832   \n56027  311848          0          0          0  -0.968293  -0.676753   \n56028  311849          0          0          0  -0.047755   1.081720   \n56029  311850          0          0          0  -1.160235   1.448068   \n\n       feature_6  feature_7  feature_9  feature_10  ...  feature_95  \\\n0              0          1          0           0  ...    0.693677   \n1              0          0          0           0  ...    0.956897   \n2              0          1          0           0  ...    0.956897   \n3              1          0          0           0  ...    0.956897   \n4              1          1          0           0  ...   -1.148864   \n...          ...        ...        ...         ...  ...         ...   \n56025          0          0          0           0  ...    0.956897   \n56026          0          0          0           0  ...    0.956897   \n56027          0          0          0           0  ...    0.956897   \n56028          1          1          0           0  ...   -1.148864   \n56029          0          1          0           0  ...    0.956897   \n\n       feature_102  feature_106  feature_107  feature_108  feature_110  \\\n0        -0.096871    -0.406229            0     0.294506            0   \n1        -0.209259     1.470164            0    -0.465459            0   \n2         0.725604     1.470164            0    -0.465459            0   \n3        -0.234802    -0.621696            0    -0.085476            0   \n4         0.413983    -0.143866            0    -0.465459            0   \n...            ...          ...          ...          ...          ...   \n56025    -0.275670     1.470164            0    -0.465459            0   \n56026    -0.255236    -0.388925            0    -0.465459            0   \n56027    -0.290996     0.331946            0     0.294506            0   \n56028    -0.183717    -0.636894            0    -0.465459            0   \n56029    -0.285887     0.458415            0    -0.465459            0   \n\n       feature_111  feature_116  feature_120  feature_121  \n0         0.399214            0    -0.165281    -0.604306  \n1        -0.374099            0    -0.165281     0.512258  \n2        -0.374099            0    -0.519843     0.326164  \n3        -0.374099            0    -0.638030    -0.604306  \n4         0.399214            0     0.071093    -0.139071  \n...            ...          ...          ...          ...  \n56025    -0.374099            0    -0.519843     0.093547  \n56026    -0.374099            0     0.543842     0.791399  \n56027    -0.374099            0     2.671212    12.887515  \n56028    -0.374099            0    -0.590755    -0.604306  \n56029    -0.374099            1     2.021182     3.559549  \n\n[56030 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>...</th>\n      <th>feature_95</th>\n      <th>feature_102</th>\n      <th>feature_106</th>\n      <th>feature_107</th>\n      <th>feature_108</th>\n      <th>feature_110</th>\n      <th>feature_111</th>\n      <th>feature_116</th>\n      <th>feature_120</th>\n      <th>feature_121</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>255821</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.733257</td>\n      <td>-0.530214</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.693677</td>\n      <td>-0.096871</td>\n      <td>-0.406229</td>\n      <td>0</td>\n      <td>0.294506</td>\n      <td>0</td>\n      <td>0.399214</td>\n      <td>0</td>\n      <td>-0.165281</td>\n      <td>-0.604306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>255822</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.173292</td>\n      <td>0.568832</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.209259</td>\n      <td>1.470164</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>-0.165281</td>\n      <td>0.512258</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>255823</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.882115</td>\n      <td>2.034226</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>0.725604</td>\n      <td>1.470164</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>-0.519843</td>\n      <td>0.326164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>255824</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.139156</td>\n      <td>-1.189641</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.234802</td>\n      <td>-0.621696</td>\n      <td>0</td>\n      <td>-0.085476</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>-0.638030</td>\n      <td>-0.604306</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>255825</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.220111</td>\n      <td>-1.116372</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.148864</td>\n      <td>0.413983</td>\n      <td>-0.143866</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>0.399214</td>\n      <td>0</td>\n      <td>0.071093</td>\n      <td>-0.139071</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56025</th>\n      <td>311846</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.152401</td>\n      <td>-1.043102</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.275670</td>\n      <td>1.470164</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>-0.519843</td>\n      <td>0.093547</td>\n    </tr>\n    <tr>\n      <th>56026</th>\n      <td>311847</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.057083</td>\n      <td>-0.969832</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.255236</td>\n      <td>-0.388925</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>0.543842</td>\n      <td>0.791399</td>\n    </tr>\n    <tr>\n      <th>56027</th>\n      <td>311848</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.968293</td>\n      <td>-0.676753</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.290996</td>\n      <td>0.331946</td>\n      <td>0</td>\n      <td>0.294506</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>2.671212</td>\n      <td>12.887515</td>\n    </tr>\n    <tr>\n      <th>56028</th>\n      <td>311849</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.047755</td>\n      <td>1.081720</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.148864</td>\n      <td>-0.183717</td>\n      <td>-0.636894</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>0</td>\n      <td>-0.590755</td>\n      <td>-0.604306</td>\n    </tr>\n    <tr>\n      <th>56029</th>\n      <td>311850</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.160235</td>\n      <td>1.448068</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.956897</td>\n      <td>-0.285887</td>\n      <td>0.458415</td>\n      <td>0</td>\n      <td>-0.465459</td>\n      <td>0</td>\n      <td>-0.374099</td>\n      <td>1</td>\n      <td>2.021182</td>\n      <td>3.559549</td>\n    </tr>\n  </tbody>\n</table>\n<p>56030 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_df[rational_features] = scaler.transform(verify_df[rational_features].values)\n",
    "verify_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.18994621, 0.64196639, 0.79247068, ..., 0.08384429, 0.44185636,\n       0.47445869])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = clf.predict_proba(verify_df.iloc[:,1:])\n",
    "result[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "           ID     score\n0      255821  0.189946\n1      255822  0.641966\n2      255823  0.792471\n3      255824  0.333674\n4      255825  0.568752\n...       ...       ...\n56025  311846  0.221008\n56026  311847  0.310434\n56027  311848  0.083844\n56028  311849  0.441856\n56029  311850  0.474459\n\n[56030 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>255821</td>\n      <td>0.189946</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>255822</td>\n      <td>0.641966</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>255823</td>\n      <td>0.792471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>255824</td>\n      <td>0.333674</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>255825</td>\n      <td>0.568752</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56025</th>\n      <td>311846</td>\n      <td>0.221008</td>\n    </tr>\n    <tr>\n      <th>56026</th>\n      <td>311847</td>\n      <td>0.310434</td>\n    </tr>\n    <tr>\n      <th>56027</th>\n      <td>311848</td>\n      <td>0.083844</td>\n    </tr>\n    <tr>\n      <th>56028</th>\n      <td>311849</td>\n      <td>0.441856</td>\n    </tr>\n    <tr>\n      <th>56029</th>\n      <td>311850</td>\n      <td>0.474459</td>\n    </tr>\n  </tbody>\n</table>\n<p>56030 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'ID':np.squeeze(verify_df.iloc[:,0].values), 'score': np.squeeze(result[:, 1])})\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "result_df.to_csv('result.csv', sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}